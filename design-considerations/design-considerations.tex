\documentclass[11pt,a4paper]{article}
\usepackage{hyperref}

\title{Design Considerations}
\author{Kevin Liew}

\begin{document}

\maketitle

\section{RPC}
	
	\paragraph{How are ResultSets transferred? Batches contained in Thrift objects?}
	Contiguous batches of TRowSet.
	\begin{verbatim}
		ie.
		ResultSet{
		    TRowSet batch1{
		        TColumn1{row1, row2},
		        TColumn2{row1, row2},
		        columnCount = 2
		    }
		    TRowSet batch2{
		        TColumn1{row3, row4},
		        TColumn2{row3, row4},
		        columnCount = 2
		    }
		}
		
	\end{verbatim}
	except that the columns are in `binaryColumns` rather than a list of TColumn after \href{https://issues.apache.org/jira/browse/HIVE-12049}{HIVE-12049}

\section{Interface}
	
	\paragraph{Should we give priority to the server or client preference for compressors? ie. the client prefers snappy first, gzip second, but the server prefers gzip first, snappy second. Should we use gzip or snappy?}

\section{Compressor-Decompressor}

	\paragraph{How can we ensure that result sets are compressed for cases where the query does not invoke any map-reduce tasks (ie. select * from table)? Our SerDe is not called so if we write our compressor within the SerDe, then some queries will not be compressed.}\
	
	\paragraph{How do we handle the case where the compressor throws an exception while handling a batch?}
	If an exception is thrown while processing a column, it won't be compressed for that batch. The client will receive it as an uncompressed column and will know that it does not need to be decompressed. The server will still try to compress that column for all other batches and those that succeed will be compressed.
	
	\paragraph{Where does decompression occur in the client? Will we operate on ColumnBasedSet or directly on TRowSet? Which files should I look at?}
	In ColumnBasedSet, we deserialize TColumn or TEnColumn from `binaryColumn` of a TRowSet.
	
	\paragraph{hive.server2.thrift.resultset.max.fetch.size: "Max number of rows sent in one Fetch RPC call by the server to the client." If the client receives batch-by-batch, then we don't need to store the batch size in TEnColumn because the client will receive and decompress each batch separately instead of receiving one huge blob with all batches? So does the client receive the batches separately or in one blob?}
	Batch-by-batch so we do not need a list of batch sizes.

\end{document}
