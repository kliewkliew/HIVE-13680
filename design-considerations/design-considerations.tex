\documentclass[11pt,a4paper]{article}
\usepackage{hyperref}

\title{Design Considerations}
\author{Kevin Liew}

\begin{document}

\maketitle

\section{RPC}
	\paragraph{How are ResultSets transferred? Batches contained in Thrift objects?}
	Contiguous batches of TRowSet.
	\begin{verbatim}
		ie.
		ResultSet{
		    TRowSet batch1{
		        TColumn1{row1, row2},
		        TColumn2{row1, row2},
		        columnCount = 2
		    }
		    TRowSet batch2{
		        TColumn1{row3, row4},
		        TColumn2{row3, row4},
		        columnCount = 2
		    }
		}
		
	\end{verbatim}
	except that the columns are in `binaryColumns` rather than a list of TColumn after \href{https://issues.apache.org/jira/browse/HIVE-12049}{HIVE-12049}

\section{Interface}
	\paragraph{We can provide a default compressor list for beeline. But for other apps using the JDBC driver, we shouldn't modify connection parameters. Should we make new versions of the JDBC driver always send all compressors in the classpath (as a handshake rather than a connection string parameter) so that performance gains are seen o-o-t-b without configuration from the user?}
	%need to provide client with a way to disable compression in this case.

\section{Compressor-Decompressor}
	\paragraph{How do we handle the case where the compressor throws an exception while handling a batch? Do we restart serialization and serialize the batch as an uncompressed column? What do we do with prior batches that were already serialized? We may have to restart serialization of the whole result set. Is there a better solution?}
	Prior batches will be compressed. If an exception is thrown while processing a column, it won't be compressed for that batch. The client will receive it as an uncompressed column and will know that it does not need to be decompressed. The server will still try to compress that column for all other batches and those that succeed will be compressed.
	
	\paragraph{Where does decompression occur in the client? Will we operate on (Encoded)ColumnBasedSet or directly on TRowSet? Which files should I look at?}
	We probably get a TRowSet and deserialize that to (Encoded)ColumnBasedSet from which we decompress batch(es).
	
	\paragraph{hive.server2.thrift.resultset.max.fetch.size: "Max number of rows sent in one Fetch RPC call by the server to the client." If the client receives batch-by-batch, then we don't need to store the batch size in TEnColumn because the client will receive and decompress each batch separately instead of receiving one huge blob with all batches? So does the client receive the batches separately or in one blob?}
	Batch-by-batch so we do not need a list of batch sizes.

\end{document}
